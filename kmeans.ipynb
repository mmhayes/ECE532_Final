{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Madeline Hayes ##\n",
    "## ECE532002 Final Project ##\n",
    "## Part 1: K-means clustering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\madel\\\\Documents\\\\Grad School\\\\Classes\\\\Fall 2020\\\\ECE532\\\\Final Project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "# set wd\n",
    "\n",
    "os.chdir(\"\\\\Users\\\\madel\\\\Documents\\\\Grad School\\\\Classes\\\\Fall 2020\\\\ECE532\\\\Final Project\")\n",
    "os.getcwd() \n",
    "#os.listdir(os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note: if you want to run this code yourself\n",
    "## re-import data (run this block) before each iteration\n",
    "## numbered 1-4\n",
    "\n",
    "# import data\n",
    "reddf = pd.read_csv(\"winequality-red.csv\",delimiter=';')\n",
    "whitedf = pd.read_csv(\"winequality-white.csv\",delimiter=';')\n",
    "\n",
    "# add color label\n",
    "reddf['color'] = str('red')\n",
    "whitedf['color']=str('white')\n",
    "    \n",
    "# stack df's \n",
    "fulldf = pd.concat([reddf, whitedf], ignore_index=True)\n",
    "#fulldf.head()\n",
    "#fulldf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hypothesis: Including all features will lead to noisy clustering \n",
    "### and a higher error rate than excluding some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. All Data, No Scaling ###\n",
    "\n",
    "## this is an unsupervised problem\n",
    "## so we remove color label\n",
    "trimdf = fulldf.drop('color',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:  [[7.61753270e+00 4.07887946e-01 2.91205373e-01 3.08405797e+00\n",
      "  6.56726759e-02 1.84515730e+01 6.36139979e+01 9.94565716e-01\n",
      "  3.25525274e+00 5.71785083e-01 1.07956816e+01 5.80982679e+00]\n",
      " [6.90508451e+00 2.87048800e-01 3.39787350e-01 7.26278626e+00\n",
      "  4.85997819e-02 3.98373773e+01 1.55951063e+02 9.94797606e-01\n",
      "  3.19015540e+00 5.00019084e-01 1.02574282e+01 5.82497274e+00]]\n",
      "SS distances: 8594875.947990824\n",
      "Number of Iterations: 18\n"
     ]
    }
   ],
   "source": [
    "## kmeans doesn't handle unscaled data well ##\n",
    "## to verify that scaling the data is appropriate, \n",
    "## we'll first run the problem without scaling ##\n",
    "\n",
    "unscaled_trimdf = trimdf\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, init='random', n_init=50, random_state=0).fit(unscaled_trimdf)\n",
    "# n_clusters: ground truth is there are two clusters, reds and whites\n",
    "# init = 'random' chooses random initial guesses for the centroids, best to avoid local minima\n",
    "# n_init = 50 is max iterations\n",
    "# random_state = 0 defines the random number generator for init\n",
    "print('Cluster Centers: ' , str(kmeans.cluster_centers_))\n",
    "print('SS distances: ' + str(kmeans.inertia_))\n",
    "print('Number of Iterations: ' + str(kmeans.n_iter_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add kmeans cluster labels to df\n",
    "\n",
    "labels = kmeans.labels_\n",
    "labels1 = labels.tolist()\n",
    "fulldf['label'] = labels1\n",
    "#fulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Error Rate: 5.190744215134459%\n",
      "White Error Rate: 26.745610453246222%\n",
      "Full Data Error Rate: 21.440664922271818%\n"
     ]
    }
   ],
   "source": [
    "## we'll check for errors by comapring 'color' and 'label' columns ##\n",
    "## assume Red = 0 ##\n",
    "## started with red = 1 but the error rate was >50% \n",
    "## switching labels doesn't change the cluster,\n",
    "## just the interpretation\n",
    "\n",
    "red_correct = []\n",
    "red_incorrect = []\n",
    "white_correct = []\n",
    "white_incorrect = []\n",
    "\n",
    "for z in list(fulldf.index.values):\n",
    "    if fulldf.at[z, 'color'] == 'red' and fulldf.at[z, 'label']==0:\n",
    "        red_correct.append(z)\n",
    "    elif fulldf.at[z,'color']=='white' and fulldf.at[z,'label']==0:\n",
    "        white_incorrect.append(z)\n",
    "    elif fulldf.at[z, 'color'] == 'red' and fulldf.at[z, 'label']==1:\n",
    "        red_incorrect.append(z)\n",
    "    elif fulldf.at[z,'color']=='white' and fulldf.at[z,'label']==1:\n",
    "        white_correct.append(z)\n",
    "\n",
    "n_reds = len(reddf.index.values)\n",
    "red_errors = len(red_incorrect)/n_reds\n",
    "print('Red Error Rate: ' + str(red_errors*100) + '%')\n",
    "n_whites = len(whitedf.index.values)\n",
    "white_errors = len(white_incorrect)/n_whites\n",
    "print('White Error Rate: ' + str(white_errors*100) + '%') \n",
    "n_total = len(fulldf.index.values)\n",
    "n_errors = (len(red_incorrect)+len(white_incorrect))/n_total\n",
    "print('Full Data Error Rate: ' + str(n_errors*100) + '%')\n",
    "\n",
    "## also want a list of the true labels here for performance evaluation,\n",
    "## see section 5 for more details\n",
    "\n",
    "true_labels1 = []\n",
    "for z in list(fulldf.index.values):\n",
    "    if fulldf.at[z, 'color'] == 'red':\n",
    "        true_labels1.append('0')\n",
    "    elif fulldf.at[z, 'color'] == 'white':\n",
    "        true_labels1.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. All Data, Scaled ###\n",
    "\n",
    "# scale and transform the data\n",
    "# since kmeans clustering doesn't handle irregularly shaped data well\n",
    "# each parameter will be scaled between 0 and 1\n",
    "X=trimdf\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(X)\n",
    "scaleddf=pd.DataFrame(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:  [[0.29206849 0.18481443 0.18996717 0.09349989 0.08957278 0.10941891\n",
      "  0.28034535 0.17506207 0.37345947 0.17378814 0.24537775 0.40030422]\n",
      " [0.26812159 0.15624969 0.19480099 0.04659765 0.06164338 0.09257737\n",
      "  0.21328209 0.10477242 0.40512758 0.17642813 0.52788939 0.56974706]]\n",
      "SS distances: 699.4912445148213\n",
      "Number of Iterations: 8\n"
     ]
    }
   ],
   "source": [
    "# run kmeans on scaled df\n",
    "kmeans = KMeans(n_clusters=2, init='random', n_init=50, random_state=0).fit(scaleddf)\n",
    "print('Cluster Centers: ' , str(kmeans.cluster_centers_))\n",
    "print('SS distances: ' + str(kmeans.inertia_))\n",
    "print('Number of Iterations: ' + str(kmeans.n_iter_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add kmeans cluster labels to df\n",
    "\n",
    "labels = kmeans.labels_\n",
    "labels2 = labels.tolist()\n",
    "fulldf['label'] = labels2\n",
    "#fulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Error Rate: 62.601626016260155%\n",
      "White Error Rate: 42.139648836259695%\n",
      "Full Data Error Rate: 47.17561951670002%\n"
     ]
    }
   ],
   "source": [
    "## we'll check for errors by comapring 'color' and 'label' columns ##\n",
    "## assume Red = 1 \n",
    "## started with red = 0 as before,\n",
    "## but the error rate was >50% for 2/3 metrics (white and total)\n",
    "## switching labels doesn't change the cluster,\n",
    "## just the interpretation, try to minimize error\n",
    "\n",
    "red_correct = []\n",
    "red_incorrect = []\n",
    "white_correct = []\n",
    "white_incorrect = []\n",
    "\n",
    "for z in list(fulldf.index.values):\n",
    "    if fulldf.at[z, 'color'] == 'red' and fulldf.at[z, 'label']==1:\n",
    "        red_correct.append(z)\n",
    "    elif fulldf.at[z,'color']=='white' and fulldf.at[z,'label']==1:\n",
    "        white_incorrect.append(z)\n",
    "    elif fulldf.at[z, 'color'] == 'red' and fulldf.at[z, 'label']==0:\n",
    "        red_incorrect.append(z)\n",
    "    elif fulldf.at[z,'color']=='white' and fulldf.at[z,'label']==0:\n",
    "        white_correct.append(z)\n",
    "\n",
    "n_reds = len(reddf.index.values)\n",
    "red_errors = len(red_incorrect)/n_reds\n",
    "print('Red Error Rate: ' + str(red_errors*100) + '%')\n",
    "n_whites = len(whitedf.index.values)\n",
    "white_errors = len(white_incorrect)/n_whites\n",
    "print('White Error Rate: ' + str(white_errors*100) + '%') \n",
    "n_total = len(fulldf.index.values)\n",
    "n_errors = (len(red_incorrect)+len(white_incorrect))/n_total\n",
    "print('Full Data Error Rate: ' + str(n_errors*100) + '%')\n",
    "\n",
    "## also want a list of the true labels here for performance evaluation,\n",
    "## see section 5 for more details\n",
    "\n",
    "true_labels2 = []\n",
    "for z in list(fulldf.index.values):\n",
    "    if fulldf.at[z, 'color'] == 'red':\n",
    "        true_labels2.append('1')\n",
    "    elif fulldf.at[z, 'color'] == 'white':\n",
    "        true_labels2.append('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. Remove Some Features, Unscaled ###\n",
    "## repeat unscaled and scaled comparison\n",
    "# alcohol content and rating show similar distributions \n",
    "# between red and white, and might not be predictive\n",
    "\n",
    "# remove quality and alcohol content\n",
    "trimdf = fulldf.drop('color',axis=1)\n",
    "trimdf = trimdf.drop('quality',axis=1)\n",
    "trimdf = trimdf.drop('alcohol',axis=1)\n",
    "#trimdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:  [[7.61753890e+00 4.07936704e-01 2.91159830e-01 3.08422914e+00\n",
      "  6.56803395e-02 1.84478430e+01 6.35975955e+01 9.94566906e-01\n",
      "  3.25523338e+00 5.71806931e-01]\n",
      " [6.90527392e+00 2.87044154e-01 3.39809212e-01 7.26151540e+00\n",
      "  4.85985282e-02 3.98344235e+01 1.55938539e+02 9.94796626e-01\n",
      "  3.19018806e+00 5.00021804e-01]]\n",
      "SS distances: 8581133.746330764\n",
      "Number of Iterations: 18\n"
     ]
    }
   ],
   "source": [
    "## kmeans doesn't handle unscaled data well ##\n",
    "## to verify that scaling the data is appropriate, \n",
    "## we'll first run the problem without scaling ##\n",
    "\n",
    "unscaled_trimdf = trimdf\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, init='random', n_init=50, random_state=0).fit(unscaled_trimdf)\n",
    "print('Cluster Centers: ' , str(kmeans.cluster_centers_))\n",
    "print('SS distances: ' + str(kmeans.inertia_))\n",
    "print('Number of Iterations: ' + str(kmeans.n_iter_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add kmeans cluster labels to df\n",
    "\n",
    "labels3 = kmeans.labels_\n",
    "labels = labels.tolist()\n",
    "fulldf['label'] = labels3\n",
    "#fulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Error Rate: 5.190744215134459%\n",
      "White Error Rate: 26.745610453246222%\n",
      "Full Data Error Rate: 21.440664922271818%\n"
     ]
    }
   ],
   "source": [
    "## we'll check for errors by comapring 'color' and 'label' columns ##\n",
    "##  assume Red = 0 \n",
    "## again, assuming labels to minimize errors since we know the labels\n",
    "\n",
    "red_correct = []\n",
    "red_incorrect = []\n",
    "white_correct = []\n",
    "white_incorrect = []\n",
    "\n",
    "for z in list(fulldf.index.values):\n",
    "    if fulldf.at[z, 'color'] == 'red' and fulldf.at[z, 'label']==0:\n",
    "        red_correct.append(z)\n",
    "    elif fulldf.at[z,'color']=='white' and fulldf.at[z,'label']==0:\n",
    "        white_incorrect.append(z)\n",
    "    elif fulldf.at[z, 'color'] == 'red' and fulldf.at[z, 'label']==1:\n",
    "        red_incorrect.append(z)\n",
    "    elif fulldf.at[z,'color']=='white' and fulldf.at[z,'label']==1:\n",
    "        white_correct.append(z)\n",
    "\n",
    "n_reds = len(reddf.index.values)\n",
    "red_errors = len(red_incorrect)/n_reds\n",
    "print('Red Error Rate: ' + str(red_errors*100) + '%')\n",
    "n_whites = len(whitedf.index.values)\n",
    "white_errors = len(white_incorrect)/n_whites\n",
    "print('White Error Rate: ' + str(white_errors*100) + '%') \n",
    "n_total = len(fulldf.index.values)\n",
    "n_errors = (len(red_incorrect)+len(white_incorrect))/n_total\n",
    "print('Full Data Error Rate: ' + str(n_errors*100) + '%')\n",
    "\n",
    "## also want a list of the true labels here for performance evaluation,\n",
    "## see section 5 for more details\n",
    "\n",
    "true_labels3 = []\n",
    "for z in list(fulldf.index.values):\n",
    "    if fulldf.at[z, 'color'] == 'red':\n",
    "        true_labels3.append('0')\n",
    "    elif fulldf.at[z, 'color'] == 'white':\n",
    "        true_labels3.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Remove Some Features, Scaled ###\n",
    "\n",
    "# as above, \n",
    "# alcohol content and rating show similar distributions \n",
    "# between red and white, and might not be predictive\n",
    "\n",
    "trimdf = fulldf.drop('color',axis=1)\n",
    "trimdf = trimdf.drop('quality',axis=1)\n",
    "trimdf = trimdf.drop('alcohol',axis=1)\n",
    "\n",
    "# scale and transform the data\n",
    "# since kmeans clustering doesn't handle irregularly shaped data\n",
    "# each parameter will be scaled between 0 and 1\n",
    "\n",
    "X=trimdf\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(X)\n",
    "scaleddf=pd.DataFrame(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:  [[0.25302069 0.1295245  0.20279466 0.08930091 0.06146042 0.1202644\n",
      "  0.30717106 0.13376085 0.36115965 0.151668  ]\n",
      " [0.36793108 0.30083686 0.16016152 0.03027309 0.12697642 0.05051527\n",
      "  0.09373545 0.18289756 0.4605017  0.24286112]]\n",
      "SS distances: 410.2867585703211\n",
      "Number of Iterations: 5\n"
     ]
    }
   ],
   "source": [
    "# run kmeans on scaled df\n",
    "kmeans = KMeans(n_clusters=2, init='random', n_init=50, random_state=0).fit(scaleddf)\n",
    "print('Cluster Centers: ' , str(kmeans.cluster_centers_))\n",
    "print('SS distances: ' + str(kmeans.inertia_))\n",
    "print('Number of Iterations: ' + str(kmeans.n_iter_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add kmeans cluster labels to df\n",
    "\n",
    "labels = kmeans.labels_\n",
    "labels4 = labels.tolist()\n",
    "fulldf['label'] = labels4\n",
    "#fulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Error Rate: 2.313946216385241%\n",
      "White Error Rate: 1.8579011841567987%\n",
      "Full Data Error Rate: 1.970140064645221%\n"
     ]
    }
   ],
   "source": [
    "## we'll check for errors by comapring 'color' and 'label' columns ##\n",
    "##  assume Red = 1 \n",
    "## again, assuming labels to minimize errors since we know the labels\n",
    "\n",
    "red_correct = []\n",
    "red_incorrect = []\n",
    "white_correct = []\n",
    "white_incorrect = []\n",
    "\n",
    "for z in list(fulldf.index.values):\n",
    "    if fulldf.at[z, 'color'] == 'red' and fulldf.at[z, 'label']==1:\n",
    "        red_correct.append(z)\n",
    "    elif fulldf.at[z,'color']=='white' and fulldf.at[z,'label']==1:\n",
    "        white_incorrect.append(z)\n",
    "    elif fulldf.at[z, 'color'] == 'red' and fulldf.at[z, 'label']==0:\n",
    "        red_incorrect.append(z)\n",
    "    elif fulldf.at[z,'color']=='white' and fulldf.at[z,'label']==0:\n",
    "        white_correct.append(z)\n",
    "\n",
    "n_reds = len(reddf.index.values)\n",
    "red_errors = len(red_incorrect)/n_reds\n",
    "print('Red Error Rate: ' + str(red_errors*100) + '%')\n",
    "n_whites = len(whitedf.index.values)\n",
    "white_errors = len(white_incorrect)/n_whites\n",
    "print('White Error Rate: ' + str(white_errors*100) + '%') \n",
    "n_total = len(fulldf.index.values)\n",
    "n_errors = (len(red_incorrect)+len(white_incorrect))/n_total\n",
    "print('Full Data Error Rate: ' + str(n_errors*100) + '%')\n",
    "\n",
    "## also want a list of the true labels here for performance evaluation,\n",
    "## see section 5 for more details\n",
    "\n",
    "true_labels4 = []\n",
    "for z in list(fulldf.index.values):\n",
    "    if fulldf.at[z, 'color'] == 'red':\n",
    "        true_labels4.append('0')\n",
    "    elif fulldf.at[z, 'color'] == 'white':\n",
    "        true_labels4.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>V-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.352393</td>\n",
       "      <td>0.287212</td>\n",
       "      <td>0.316481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.352393</td>\n",
       "      <td>0.287212</td>\n",
       "      <td>0.316481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.842913</td>\n",
       "      <td>0.829359</td>\n",
       "      <td>0.836081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iteration  Homogeneity  Completeness   V-Score\n",
       "0          1     0.352393      0.287212  0.316481\n",
       "1          2     0.001556      0.001283  0.001406\n",
       "2          3     0.352393      0.287212  0.316481\n",
       "3          4     0.842913      0.829359  0.836081"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 5. Evaluating Performance ### \n",
    "\n",
    "## using homogeneity, completeness, and v-measure\n",
    "## need to compare lists of true labels and predicted labels\n",
    "## these will be for each run, as the 0 or 1 label was different\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "its = [1, 2, 3, 4]\n",
    "homs = []\n",
    "coms = []\n",
    "vscores = []\n",
    "\n",
    "## iteration 1: all features, unscaled\n",
    "it1hom = metrics.homogeneity_score(true_labels1, labels1)\n",
    "homs.append(it1hom)\n",
    "it1com = metrics.completeness_score(true_labels1, labels1)\n",
    "coms.append(it1com)\n",
    "it1v = metrics.v_measure_score(true_labels1, labels1)\n",
    "vscores.append(it1v)\n",
    "\n",
    "## iteration 2: all features, scaled\n",
    "it2hom = metrics.homogeneity_score(true_labels2, labels2)\n",
    "homs.append(it2hom)\n",
    "it2com = metrics.completeness_score(true_labels2, labels2)\n",
    "coms.append(it2com)\n",
    "it2v = metrics.v_measure_score(true_labels2, labels2)\n",
    "vscores.append(it2v)\n",
    "\n",
    "## iteration 3: selected features, unscaled\n",
    "it3hom = metrics.homogeneity_score(true_labels3, labels3)\n",
    "homs.append(it3hom)\n",
    "it3com = metrics.completeness_score(true_labels3, labels3)\n",
    "coms.append(it3com)\n",
    "it3v = metrics.v_measure_score(true_labels3, labels3)\n",
    "vscores.append(it3v)\n",
    "\n",
    "## iteration 4: selected features, unscaled\n",
    "it4hom = metrics.homogeneity_score(true_labels4, labels4)\n",
    "homs.append(it4hom)\n",
    "it4com = metrics.completeness_score(true_labels4, labels4)\n",
    "coms.append(it4com)\n",
    "it4v = metrics.v_measure_score(true_labels4, labels4)\n",
    "vscores.append(it4v)\n",
    "\n",
    "#import dataframe_image as dfi\n",
    "\n",
    "vscoredf = pd.DataFrame(columns = ['Iteration', 'Homogeneity', 'Completeness','V-Score'])\n",
    "vscoredf['Iteration']=its\n",
    "vscoredf['Homogeneity']=homs\n",
    "vscoredf['Completeness']=coms\n",
    "vscoredf['V-Score']=vscores\n",
    "vscoredf.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
